{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "L04qs.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ttalarico003/GCMachineLearning/blob/main/L04qs_TonyT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFrzPlyoikd9"
      },
      "source": [
        "What do you think will happen to the accuracy of training a neural network as the number of layers increases? Try training a neural network for the MNIST data using more layers to see what happens. Speculate as to why you are seeing what you are seeing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZ27Nqb8TBKx",
        "outputId": "304eb915-6dda-4a26-a52c-351b151ee0a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Read in the mnist digit dataset\n",
        "\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import check_random_state\n",
        "import random\n",
        "from sklearn import tree\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "X, y = fetch_openml('mnist_784', version=1, return_X_y=True, as_frame=False)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KB0MV4C1jCAC"
      },
      "source": [
        "Next, we will divide the data into a training set and test set, randomly selecting 5000 examples for training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJ2-XGCVTBK3"
      },
      "source": [
        "train_samples = 5000\n",
        "\n",
        "random_state = check_random_state(0)\n",
        "permutation = random_state.permutation(X.shape[0])\n",
        "X = X[permutation]\n",
        "y = y[permutation]\n",
        "X = X.reshape((X.shape[0], -1))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, train_size=train_samples, test_size=10000)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTpGs2l-kdOs"
      },
      "source": [
        "Now, we will try 10 hidden units in each of 1 to 10 layers, keeping track of the min/mean/max accuracy of models at each number of layers over ten runs.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFoZESbCupY3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45e918c5-42c0-4dec-b84e-7322680b144a"
      },
      "source": [
        "reps = 10\n",
        "for i in range(1,11):\n",
        "  nhidden = i*[100]\n",
        "  accsum,accmin,accmax = 0.0,1.0,0.0\n",
        "  for r in range(reps):\n",
        "    clf = MLPClassifier(hidden_layer_sizes=nhidden, max_iter = 10000)\n",
        "    clf.fit(X_train, y_train)\n",
        "    score = clf.score(X_test, y_test)\n",
        "    accsum += score\n",
        "    accmin = min(accmin, score)\n",
        "    accmax = max(accmax, score)\n",
        "  print(i, accmin, accsum/reps, accmax)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 0.8814 0.8906699999999999 0.9039\n",
            "2 0.8656 0.8710700000000001 0.8807\n",
            "3 0.8581 0.86602 0.8723\n",
            "4 0.8675 0.87389 0.8781\n",
            "5 0.8809 0.8904399999999999 0.9007\n",
            "6 0.8928 0.9007200000000001 0.9074\n",
            "7 0.9071 0.9125499999999999 0.9224\n",
            "8 0.9121 0.9218499999999998 0.9344\n",
            "9 0.9176 0.9259499999999999 0.9366\n",
            "10 0.9151 0.9298400000000001 0.9405\n"
          ]
        }
      ]
    }
  ]
}