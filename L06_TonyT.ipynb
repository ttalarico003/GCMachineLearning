{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "L06.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ttalarico003/GCMachineLearning/blob/main/L06_TonyT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-H4o3Mtf8I1"
      },
      "source": [
        "In this noteobook, we will build a spam detector using two different models, a decision tree and a naive Bayes model. A naive Bayes classifier calculates the probability of a sequence of words belonging to a class as proprotional to the product of the probability of each item in a sequence given the class.\n",
        "\n",
        "Below we import the libraries we'll be using.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysfO6y4TygzU"
      },
      "source": [
        "from sklearn import tree\n",
        "import graphviz\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-flSIqbs4us"
      },
      "source": [
        "Next we'll write a function to process the data into a dictionary of words and their number of occurances, `word_dict`, and a count of the number of words total, `lexiconsize`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwlVeKj9GLFx"
      },
      "source": [
        "# read in the vocabulary file\n",
        "def readvocab(vocab_path=\"vocab.txt\"):\n",
        "   # keep track of the number of words\n",
        "    lexiconsize = 0\n",
        "   # initialize an empty dictionary\n",
        "    word_dict = {}\n",
        "   # create a feature for unknown words\n",
        "    word_dict[\"@unk\"] = lexiconsize\n",
        "    lexiconsize += 1\n",
        "   # read in the vocabular file\n",
        "    with open(vocab_path, \"r\") as f:\n",
        "        data = f.readlines()\n",
        "   # Process the file a line at a time.\n",
        "    for line in data:\n",
        "        # The count is the first 3 characters\n",
        "        count = int(line[0:4])\n",
        "        # The word is the rest of the string\n",
        "        token = line[5:-1]\n",
        "       # Create a feature if it’s appeared at least twice\n",
        "        if count > 1:\n",
        "            word_dict[token] = lexiconsize\n",
        "            lexiconsize += 1\n",
        "    # squirrel away the total size for later reference\n",
        "    word_dict[\"@size\"] = lexiconsize\n",
        "    return(word_dict)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M49cH5GGxTuG"
      },
      "source": [
        "We will download the vocabulary data from GitHub, `vocab.txt`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TZ7Eft7CoRS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db8d4a70-c64b-4402-ef9b-213506d89464"
      },
      "source": [
        "!wget https://github.com/mlittmancs/great_courses_ml/raw/master/data/vocab.txt"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-11-17 19:28:29--  https://github.com/mlittmancs/great_courses_ml/raw/master/data/vocab.txt\n",
            "Resolving github.com (github.com)... 140.82.121.3\n",
            "Connecting to github.com (github.com)|140.82.121.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/mlittmancs/great_courses_ml/master/data/vocab.txt [following]\n",
            "--2023-11-17 19:28:29--  https://raw.githubusercontent.com/mlittmancs/great_courses_ml/master/data/vocab.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 90153 (88K) [text/plain]\n",
            "Saving to: ‘vocab.txt’\n",
            "\n",
            "vocab.txt           100%[===================>]  88.04K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2023-11-17 19:28:29 (12.1 MB/s) - ‘vocab.txt’ saved [90153/90153]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fL_XRUDS34IL"
      },
      "source": [
        "Next, we write a `tokenize` function to turn each word into a list of the length of the number words.  Every item in the list is a count of the number of times a given word occurs in the list."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kg0eeOYEbKBP"
      },
      "source": [
        "# Turn string str into a vector.\n",
        "def tokenize(email_string, word_dict):\n",
        "  # initially the vector is all zeros\n",
        "  vec = [0 for i in range(word_dict[\"@size\"])]\n",
        "  # for each word\n",
        "  for t in email_string.split(\" \"):\n",
        "   # if the word has a feature, add one to the corresponding feature\n",
        "    if t in word_dict: vec[word_dict[t]] += 1\n",
        "   # otherwise, count it as an unk\n",
        "    else: vec[word_dict[\"@unk\"]] += 1\n",
        "  return(vec)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wF_Qo8nEJijp"
      },
      "source": [
        "From here, we write a `getdat` function to convert the file we downloaded into two lists:\n",
        "\n",
        "- `dat`: a list of lists of tokenized words\n",
        "- `labs`: a list of labels associated with the email being spam or not spam"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "821K7VKScgx5"
      },
      "source": [
        "# read in labeled examples and turn the strings into vectors\n",
        "def getdat(filename, word_dict):\n",
        "    with open(filename, \"r\") as f:\n",
        "        data = f.readlines()\n",
        "    dat = []\n",
        "    labs = []\n",
        "    for line in data:\n",
        "        labs = labs + [int(line[0])]\n",
        "        dat = dat + [tokenize(line[2:], word_dict)]\n",
        "    return(dat, labs)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcrtGdGMcqEg"
      },
      "source": [
        "Now we'll download the train and test data from GitHub"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpS1CVviDFIq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a00bd826-9732-40ad-b461-36499ceca9e6"
      },
      "source": [
        "!wget https://github.com/mlittmancs/great_courses_ml/raw/master/data/spam-test.csv\n",
        "!wget https://github.com/mlittmancs/great_courses_ml/raw/master/data/spam-train.csv"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-11-17 19:29:24--  https://github.com/mlittmancs/great_courses_ml/raw/master/data/spam-test.csv\n",
            "Resolving github.com (github.com)... 140.82.121.3\n",
            "Connecting to github.com (github.com)|140.82.121.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/mlittmancs/great_courses_ml/master/data/spam-test.csv [following]\n",
            "--2023-11-17 19:29:24--  https://raw.githubusercontent.com/mlittmancs/great_courses_ml/master/data/spam-test.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 166047 (162K) [text/plain]\n",
            "Saving to: ‘spam-test.csv’\n",
            "\n",
            "spam-test.csv       100%[===================>] 162.16K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2023-11-17 19:29:25 (1.44 MB/s) - ‘spam-test.csv’ saved [166047/166047]\n",
            "\n",
            "--2023-11-17 19:29:25--  https://github.com/mlittmancs/great_courses_ml/raw/master/data/spam-train.csv\n",
            "Resolving github.com (github.com)... 140.82.121.4\n",
            "Connecting to github.com (github.com)|140.82.121.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/mlittmancs/great_courses_ml/master/data/spam-train.csv [following]\n",
            "--2023-11-17 19:29:25--  https://raw.githubusercontent.com/mlittmancs/great_courses_ml/master/data/spam-train.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 289027 (282K) [text/plain]\n",
            "Saving to: ‘spam-train.csv’\n",
            "\n",
            "spam-train.csv      100%[===================>] 282.25K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2023-11-17 19:29:25 (2.13 MB/s) - ‘spam-train.csv’ saved [289027/289027]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPPYYmSxdTk_"
      },
      "source": [
        "With these train and test datasets, we'll build create the data and labels we will use to train and use to test our naive Bayes model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIXOxbdFDpK4"
      },
      "source": [
        "word_dict = readvocab()\n",
        "traindat, trainlabs = getdat(\"spam-train.csv\", word_dict)\n",
        "testdat, testlabs = getdat(\"spam-test.csv\", word_dict)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kNVQA_LhdE6"
      },
      "source": [
        "With the training and testing data, we can fit a decision tree with 6 decision rules and print out the accuracy on the test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qX25q8kgdqS3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b65937b-a44b-4950-fb67-725e1c4cc020"
      },
      "source": [
        "clf = tree.DecisionTreeClassifier(max_leaf_nodes = 6)\n",
        "clf = clf.fit(traindat, trainlabs)\n",
        "\n",
        "yhat = clf.predict(testdat)\n",
        "\n",
        "sum([yhat[i] == testlabs[i] for i in range(len(testdat))])/len(testdat)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9415"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLpCR7GXipHG"
      },
      "source": [
        "We now will create a list of the words in our wordlist and use it to print the decision tree we have learned"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIA3MiRfeCGx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 518
        },
        "outputId": "497aa128-74ad-4881-de7f-e473e915906b"
      },
      "source": [
        "wordlist = list(word_dict.keys())[:-1]\n",
        "dot_data = tree.export_graphviz(clf, feature_names=wordlist,\n",
        "                      filled=True, rounded=True)\n",
        "graph = graphviz.Source(dot_data)\n",
        "graph"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: Tree Pages: 1 -->\n<svg width=\"629pt\" height=\"373pt\"\n viewBox=\"0.00 0.00 629.00 373.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 369)\">\n<title>Tree</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-369 625,-369 625,4 -4,4\"/>\n<!-- 0 -->\n<g id=\"node1\" class=\"node\">\n<title>0</title>\n<path fill=\"#e99457\" stroke=\"black\" d=\"M419,-365C419,-365 311,-365 311,-365 305,-365 299,-359 299,-353 299,-353 299,-309 299,-309 299,-303 305,-297 311,-297 311,-297 419,-297 419,-297 425,-297 431,-303 431,-309 431,-309 431,-353 431,-353 431,-359 425,-365 419,-365\"/>\n<text text-anchor=\"middle\" x=\"365\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">call &lt;= 0.5</text>\n<text text-anchor=\"middle\" x=\"365\" y=\"-334.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.231</text>\n<text text-anchor=\"middle\" x=\"365\" y=\"-319.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3572</text>\n<text text-anchor=\"middle\" x=\"365\" y=\"-304.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3096, 476]</text>\n</g>\n<!-- 1 -->\n<g id=\"node2\" class=\"node\">\n<title>1</title>\n<path fill=\"#e78c4b\" stroke=\"black\" d=\"M346,-261C346,-261 238,-261 238,-261 232,-261 226,-255 226,-249 226,-249 226,-205 226,-205 226,-199 232,-193 238,-193 238,-193 346,-193 346,-193 352,-193 358,-199 358,-205 358,-205 358,-249 358,-249 358,-255 352,-261 346,-261\"/>\n<text text-anchor=\"middle\" x=\"292\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">txt &lt;= 0.5</text>\n<text text-anchor=\"middle\" x=\"292\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.152</text>\n<text text-anchor=\"middle\" x=\"292\" y=\"-215.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3208</text>\n<text text-anchor=\"middle\" x=\"292\" y=\"-200.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2943, 265]</text>\n</g>\n<!-- 0&#45;&gt;1 -->\n<g id=\"edge1\" class=\"edge\">\n<title>0&#45;&gt;1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M341.3,-296.88C335.05,-288.15 328.23,-278.62 321.71,-269.51\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"324.5,-267.39 315.83,-261.3 318.81,-271.47 324.5,-267.39\"/>\n<text text-anchor=\"middle\" x=\"311.74\" y=\"-282.26\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\n</g>\n<!-- 2 -->\n<g id=\"node7\" class=\"node\">\n<title>2</title>\n<path fill=\"#c9e4f8\" stroke=\"black\" d=\"M489.5,-261C489.5,-261 388.5,-261 388.5,-261 382.5,-261 376.5,-255 376.5,-249 376.5,-249 376.5,-205 376.5,-205 376.5,-199 382.5,-193 388.5,-193 388.5,-193 489.5,-193 489.5,-193 495.5,-193 501.5,-199 501.5,-205 501.5,-205 501.5,-249 501.5,-249 501.5,-255 495.5,-261 489.5,-261\"/>\n<text text-anchor=\"middle\" x=\"439\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">i &lt;= 0.5</text>\n<text text-anchor=\"middle\" x=\"439\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.487</text>\n<text text-anchor=\"middle\" x=\"439\" y=\"-215.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 364</text>\n<text text-anchor=\"middle\" x=\"439\" y=\"-200.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [153, 211]</text>\n</g>\n<!-- 0&#45;&gt;2 -->\n<g id=\"edge6\" class=\"edge\">\n<title>0&#45;&gt;2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M389.03,-296.88C395.36,-288.15 402.27,-278.62 408.88,-269.51\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"411.8,-271.45 414.84,-261.3 406.14,-267.34 411.8,-271.45\"/>\n<text text-anchor=\"middle\" x=\"418.77\" y=\"-282.29\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\n</g>\n<!-- 3 -->\n<g id=\"node3\" class=\"node\">\n<title>3</title>\n<path fill=\"#e78945\" stroke=\"black\" d=\"M216,-157C216,-157 108,-157 108,-157 102,-157 96,-151 96,-145 96,-145 96,-101 96,-101 96,-95 102,-89 108,-89 108,-89 216,-89 216,-89 222,-89 228,-95 228,-101 228,-101 228,-145 228,-145 228,-151 222,-157 216,-157\"/>\n<text text-anchor=\"middle\" x=\"162\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">www &lt;= 0.5</text>\n<text text-anchor=\"middle\" x=\"162\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.109</text>\n<text text-anchor=\"middle\" x=\"162\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3120</text>\n<text text-anchor=\"middle\" x=\"162\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2939, 181]</text>\n</g>\n<!-- 1&#45;&gt;3 -->\n<g id=\"edge2\" class=\"edge\">\n<title>1&#45;&gt;3</title>\n<path fill=\"none\" stroke=\"black\" d=\"M249.79,-192.88C237.87,-183.53 224.78,-173.26 212.43,-163.57\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"214.47,-160.72 204.44,-157.3 210.15,-166.23 214.47,-160.72\"/>\n</g>\n<!-- 4 -->\n<g id=\"node6\" class=\"node\">\n<title>4</title>\n<path fill=\"#42a2e6\" stroke=\"black\" d=\"M336,-149.5C336,-149.5 258,-149.5 258,-149.5 252,-149.5 246,-143.5 246,-137.5 246,-137.5 246,-108.5 246,-108.5 246,-102.5 252,-96.5 258,-96.5 258,-96.5 336,-96.5 336,-96.5 342,-96.5 348,-102.5 348,-108.5 348,-108.5 348,-137.5 348,-137.5 348,-143.5 342,-149.5 336,-149.5\"/>\n<text text-anchor=\"middle\" x=\"297\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.087</text>\n<text text-anchor=\"middle\" x=\"297\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 88</text>\n<text text-anchor=\"middle\" x=\"297\" y=\"-104.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [4, 84]</text>\n</g>\n<!-- 1&#45;&gt;4 -->\n<g id=\"edge5\" class=\"edge\">\n<title>1&#45;&gt;4</title>\n<path fill=\"none\" stroke=\"black\" d=\"M293.62,-192.88C294.15,-182.22 294.73,-170.35 295.26,-159.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"298.76,-159.68 295.75,-149.52 291.76,-159.34 298.76,-159.68\"/>\n</g>\n<!-- 7 -->\n<g id=\"node4\" class=\"node\">\n<title>7</title>\n<path fill=\"#e68743\" stroke=\"black\" d=\"M120,-53C120,-53 12,-53 12,-53 6,-53 0,-47 0,-41 0,-41 0,-12 0,-12 0,-6 6,0 12,0 12,0 120,0 120,0 126,0 132,-6 132,-12 132,-12 132,-41 132,-41 132,-47 126,-53 120,-53\"/>\n<text text-anchor=\"middle\" x=\"66\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.089</text>\n<text text-anchor=\"middle\" x=\"66\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3081</text>\n<text text-anchor=\"middle\" x=\"66\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2938, 143]</text>\n</g>\n<!-- 3&#45;&gt;7 -->\n<g id=\"edge3\" class=\"edge\">\n<title>3&#45;&gt;7</title>\n<path fill=\"none\" stroke=\"black\" d=\"M128.42,-88.95C119.04,-79.71 108.84,-69.67 99.46,-60.44\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"101.73,-57.76 92.15,-53.24 96.82,-62.75 101.73,-57.76\"/>\n</g>\n<!-- 8 -->\n<g id=\"node5\" class=\"node\">\n<title>8</title>\n<path fill=\"#3ea0e6\" stroke=\"black\" d=\"M240,-53C240,-53 162,-53 162,-53 156,-53 150,-47 150,-41 150,-41 150,-12 150,-12 150,-6 156,0 162,0 162,0 240,0 240,0 246,0 252,-6 252,-12 252,-12 252,-41 252,-41 252,-47 246,-53 240,-53\"/>\n<text text-anchor=\"middle\" x=\"201\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.05</text>\n<text text-anchor=\"middle\" x=\"201\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 39</text>\n<text text-anchor=\"middle\" x=\"201\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 38]</text>\n</g>\n<!-- 3&#45;&gt;8 -->\n<g id=\"edge4\" class=\"edge\">\n<title>3&#45;&gt;8</title>\n<path fill=\"none\" stroke=\"black\" d=\"M175.64,-88.95C179.15,-80.44 182.94,-71.26 186.5,-62.65\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"189.8,-63.82 190.38,-53.24 183.33,-61.15 189.8,-63.82\"/>\n</g>\n<!-- 5 -->\n<g id=\"node8\" class=\"node\">\n<title>5</title>\n<path fill=\"#6db7ec\" stroke=\"black\" d=\"M480.5,-157C480.5,-157 387.5,-157 387.5,-157 381.5,-157 375.5,-151 375.5,-145 375.5,-145 375.5,-101 375.5,-101 375.5,-95 381.5,-89 387.5,-89 387.5,-89 480.5,-89 480.5,-89 486.5,-89 492.5,-95 492.5,-101 492.5,-101 492.5,-145 492.5,-145 492.5,-151 486.5,-157 480.5,-157\"/>\n<text text-anchor=\"middle\" x=\"434\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">me &lt;= 0.5</text>\n<text text-anchor=\"middle\" x=\"434\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.329</text>\n<text text-anchor=\"middle\" x=\"434\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 255</text>\n<text text-anchor=\"middle\" x=\"434\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [53, 202]</text>\n</g>\n<!-- 2&#45;&gt;5 -->\n<g id=\"edge7\" class=\"edge\">\n<title>2&#45;&gt;5</title>\n<path fill=\"none\" stroke=\"black\" d=\"M437.38,-192.88C436.98,-184.78 436.55,-175.98 436.13,-167.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"439.62,-167.12 435.63,-157.3 432.63,-167.46 439.62,-167.12\"/>\n</g>\n<!-- 6 -->\n<g id=\"node11\" class=\"node\">\n<title>6</title>\n<path fill=\"#e78c4b\" stroke=\"black\" d=\"M609,-149.5C609,-149.5 523,-149.5 523,-149.5 517,-149.5 511,-143.5 511,-137.5 511,-137.5 511,-108.5 511,-108.5 511,-102.5 517,-96.5 523,-96.5 523,-96.5 609,-96.5 609,-96.5 615,-96.5 621,-102.5 621,-108.5 621,-108.5 621,-137.5 621,-137.5 621,-143.5 615,-149.5 609,-149.5\"/>\n<text text-anchor=\"middle\" x=\"566\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.152</text>\n<text text-anchor=\"middle\" x=\"566\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 109</text>\n<text text-anchor=\"middle\" x=\"566\" y=\"-104.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [100, 9]</text>\n</g>\n<!-- 2&#45;&gt;6 -->\n<g id=\"edge10\" class=\"edge\">\n<title>2&#45;&gt;6</title>\n<path fill=\"none\" stroke=\"black\" d=\"M480.23,-192.88C495.02,-181.01 511.66,-167.65 526.31,-155.88\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"528.62,-158.51 534.23,-149.52 524.24,-153.05 528.62,-158.51\"/>\n</g>\n<!-- 9 -->\n<g id=\"node9\" class=\"node\">\n<title>9</title>\n<path fill=\"#4ea7e8\" stroke=\"black\" d=\"M442.5,-53C442.5,-53 349.5,-53 349.5,-53 343.5,-53 337.5,-47 337.5,-41 337.5,-41 337.5,-12 337.5,-12 337.5,-6 343.5,0 349.5,0 349.5,0 442.5,0 442.5,0 448.5,0 454.5,-6 454.5,-12 454.5,-12 454.5,-41 454.5,-41 454.5,-47 448.5,-53 442.5,-53\"/>\n<text text-anchor=\"middle\" x=\"396\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.171</text>\n<text text-anchor=\"middle\" x=\"396\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 222</text>\n<text text-anchor=\"middle\" x=\"396\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [21, 201]</text>\n</g>\n<!-- 5&#45;&gt;9 -->\n<g id=\"edge8\" class=\"edge\">\n<title>5&#45;&gt;9</title>\n<path fill=\"none\" stroke=\"black\" d=\"M420.71,-88.95C417.29,-80.44 413.6,-71.26 410.13,-62.65\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"413.33,-61.21 406.35,-53.24 406.83,-63.82 413.33,-61.21\"/>\n</g>\n<!-- 10 -->\n<g id=\"node10\" class=\"node\">\n<title>10</title>\n<path fill=\"#e6853f\" stroke=\"black\" d=\"M563,-53C563,-53 485,-53 485,-53 479,-53 473,-47 473,-41 473,-41 473,-12 473,-12 473,-6 479,0 485,0 485,0 563,0 563,0 569,0 575,-6 575,-12 575,-12 575,-41 575,-41 575,-47 569,-53 563,-53\"/>\n<text text-anchor=\"middle\" x=\"524\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.059</text>\n<text text-anchor=\"middle\" x=\"524\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 33</text>\n<text text-anchor=\"middle\" x=\"524\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [32, 1]</text>\n</g>\n<!-- 5&#45;&gt;10 -->\n<g id=\"edge9\" class=\"edge\">\n<title>5&#45;&gt;10</title>\n<path fill=\"none\" stroke=\"black\" d=\"M465.48,-88.95C474.19,-79.8 483.65,-69.87 492.37,-60.71\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"495.13,-62.89 499.49,-53.24 490.06,-58.06 495.13,-62.89\"/>\n</g>\n</g>\n</svg>\n",
            "text/plain": [
              "<graphviz.sources.Source at 0x7b93f1711450>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3uB28SYZi0jF"
      },
      "source": [
        "How does the number of decision rules affect the accuracy of the model? We'll retrain the model 29 times to see how the accuracy changes as we increase the number of decision rules from 2 to 30."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbZM0Vj4eCkV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b795b22d-68a2-4683-c24f-18eaadb30387"
      },
      "source": [
        "for leaves in range(2, 31):\n",
        "  clf = tree.DecisionTreeClassifier(max_leaf_nodes = leaves)\n",
        "  clf = clf.fit(traindat, trainlabs)\n",
        "  yhat = clf.predict(testdat)\n",
        "  acc = sum([yhat[i] == testlabs[i] for i in range(len(testdat))])/len(testdat)\n",
        "  print(leaves,acc)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2 0.888\n",
            "3 0.913\n",
            "4 0.931\n",
            "5 0.937\n",
            "6 0.9415\n",
            "7 0.942\n",
            "8 0.9385\n",
            "9 0.9425\n",
            "10 0.945\n",
            "11 0.9475\n",
            "12 0.949\n",
            "13 0.952\n",
            "14 0.9525\n",
            "15 0.9535\n",
            "16 0.9535\n",
            "17 0.96\n",
            "18 0.96\n",
            "19 0.9595\n",
            "20 0.959\n",
            "21 0.958\n",
            "22 0.959\n",
            "23 0.957\n",
            "24 0.958\n",
            "25 0.958\n",
            "26 0.957\n",
            "27 0.9575\n",
            "28 0.959\n",
            "29 0.959\n",
            "30 0.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzPXwVdEjM2b"
      },
      "source": [
        "Let's now fit a naive Bayes model and print the accuracy of the model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKyZtRHgkWJT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f614f077-adcb-498d-da18-ce26048f3652"
      },
      "source": [
        "clf = MultinomialNB().fit(traindat, trainlabs)\n",
        "clf = clf.fit(traindat, trainlabs)\n",
        "yhat = clf.predict(testdat)\n",
        "acc = sum([yhat[i] == testlabs[i] for i in range(len(testdat))])/len(testdat)\n",
        "acc"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.985"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tuVd6zVpdvJ"
      },
      "source": [
        "We can also calculate the confusion matrix of the model, a table of the following counts:\n",
        "\n",
        "True Negatives False Positives\n",
        "\n",
        "False Negatives True Positives"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usa3eGx6eK4w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "359509a7-76a6-495d-cd42-51be0dc46094"
      },
      "source": [
        "print(confusion_matrix(testlabs, yhat))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1724    5]\n",
            " [  25  246]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v91_evRmkMvx"
      },
      "source": [
        "Let's visualize how Naive Bayes combines information from words in a sentence to make a judgement."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpNi9hRalhK6"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def plotsentence(sentence, clf):\n",
        "  acc = 1.0\n",
        "  labs = []\n",
        "  facs = []\n",
        "  factor = np.exp(clf.class_log_prior_[0]- clf.class_log_prior_[1])\n",
        "  labs += [\"PRIOR\"]\n",
        "  facs += [factor]\n",
        "  acc *= factor\n",
        "  for w in sentence:\n",
        "    i = word_dict[w]\n",
        "    factor = np.exp(clf.feature_log_prob_[0][i]- clf.feature_log_prob_[1][i])\n",
        "    labs += [w]\n",
        "    facs += [factor]\n",
        "    acc *= factor\n",
        "  labs += [\"POST\"]\n",
        "  facs += [acc]\n",
        "  return((labs,facs))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NA6qDQQ8qque",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1685f2a-468a-47c6-f223-7660c01b7e8d"
      },
      "source": [
        "(labs,facs) = plotsentence(['yo', 'come', 'over', 'carlos', 'will', 'be', 'here', 'soon'], clf)\n",
        "facs = [ fac if fac >= 1.0 else -1/fac for fac in facs ]\n",
        "[(l,round(f,1)) for (l,f) in zip(labs,facs)]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('PRIOR', 6.5),\n",
              " ('yo', 8.0),\n",
              " ('come', 15.5),\n",
              " ('over', 1.4),\n",
              " ('carlos', 4.9),\n",
              " ('will', 1.9),\n",
              " ('be', 1.4),\n",
              " ('here', 6.7),\n",
              " ('soon', 3.4),\n",
              " ('POST', 347592.0)]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmveTDZ4y_jo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61abbabb-b4a7-4ffa-b10d-0299121905c7"
      },
      "source": [
        "(labs,facs) = plotsentence(['congratulations', 'thanks', 'to', 'a', 'good', 'friend', 'u', 'have', 'won'], clf)\n",
        "facs = [ fac if fac >= 1.0 else -1/fac for fac in facs ]\n",
        "[(l,round(f,1)) for (l,f) in zip(labs,facs)]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('PRIOR', 6.5),\n",
              " ('congratulations', -11.4),\n",
              " ('thanks', -1.1),\n",
              " ('to', -1.4),\n",
              " ('a', -1.2),\n",
              " ('good', 4.7),\n",
              " ('friend', -1.3),\n",
              " ('u', 2.0),\n",
              " ('have', -1.1),\n",
              " ('won', -12.6),\n",
              " ('POST', -6.0)]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    }
  ]
}